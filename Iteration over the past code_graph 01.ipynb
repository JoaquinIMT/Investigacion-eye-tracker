{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8528084e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pynput\n",
      "  Downloading pynput-1.7.3-py2.py3-none-any.whl (99 kB)\n",
      "Requirement already satisfied: six in c:\\users\\moust\\anaconda3\\lib\\site-packages (from pynput) (1.15.0)\n",
      "Installing collected packages: pynput\n",
      "Successfully installed pynput-1.7.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install pynput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bc984e9",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a5a0756d7e7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0msc_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyautogui\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscreenshot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyscreeze\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_PILLOW_UNAVAILABLE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mPyScreezeException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The Pillow package is required to use this function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrappedFunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pyscreeze\\__init__.py\u001b[0m in \u001b[0;36m_screenshot_win32\u001b[1;34m(imageFilename, region)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[1;31m# TODO - Use the winapi to get a screenshot, and compare performance with ImageGrab.grab()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;31m# https://stackoverflow.com/a/3586280/1893164\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageGrab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mregion\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mregion\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'region argument must be a tuple of four ints'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\PIL\\ImageGrab.py\u001b[0m in \u001b[0;36mgrab\u001b[1;34m(bbox, include_layered_windows, all_screens, xdisplay)\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"win32\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m             offset, size, data = Image.core.grabscreen_win32(\n\u001b[0m\u001b[0;32m     44\u001b[0m                 \u001b[0minclude_layered_windows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_screens\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m             )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pyautogui\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "while True:\n",
    "    sc_img = pyautogui.screenshot()\n",
    "    frame = np.array(sc_img)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    cv2.imshow('showing2', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321fe638",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import socket\n",
    "import numpy as np\n",
    "import time\n",
    "import pyautogui\n",
    "\n",
    "from static_functions import *\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "def main():\n",
    "    #ms = socket.socket()\n",
    "    #ms.bind(('localhost',5000))\n",
    "    #ms.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)\n",
    "    #ms.listen(5)\n",
    "    blob_detector_params = cv2.SimpleBlobDetector_Params()\n",
    "    blob_detector_params.filterByArea = True\n",
    "    blob_detector_params.maxArea = 150\n",
    "    blob_detector = cv2.SimpleBlobDetector_create(blob_detector_params)\n",
    "    #cap = cv2.VideoCapture(0)\n",
    "    inas=0\n",
    "    graph = Graph(100, 60)\n",
    "    graph2 = Graph(100, 60)\n",
    "    while True:\n",
    "        #_, frame = cap.read()\n",
    "        sc_img = pyautogui.screenshot()\n",
    "        frame = np.array(sc_img)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        face_frame, face_coords = detect_faces(frame, face_cascade)\n",
    "        if face_frame is not None:\n",
    "            eyes = detect_eyes(face_frame, eye_cascade)\n",
    "            eye_coords = []\n",
    "            eyes_frames = []\n",
    "            for index,eye in enumerate(eyes):\n",
    "                if eye is not None:\n",
    "                    if index == 0:\n",
    "                        graph2.update = True\n",
    "                    if index == 1:\n",
    "                        graph.update = True\n",
    "                    eye = cut_eyebrows(eye)\n",
    "                    cv2.imshow('left_eye', eye)\n",
    "                    keypoints = blob_process(eye, blob_detector)\n",
    "                    eye = cv2.drawKeypoints(eye, keypoints, eye, (0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "                    kp_coordinate = (0,0)\n",
    "                    kp_size = 0\n",
    "                    for kp in keypoints:\n",
    "                        if kp.size > kp_size:\n",
    "                            kp_size = kp.size\n",
    "                            kp_coordinate = kp.pt\n",
    "                    if len(keypoints) > 0:\n",
    "                        eyes_frames.append(eye)\n",
    "                        eye_coords.append(kp_coordinate)\n",
    "                        kp_x, kp_y = face_scale(eye.shape[:2],(kp_coordinate[0],kp_coordinate[1]))\n",
    "                        if graph2.update:\n",
    "                            graph2.update_frame(kp_y,kp_x,eye)\n",
    "                            graph2.update = False\n",
    "                        if graph.update:\n",
    "                            graph.update_frame(kp_y,kp_x,eye)\n",
    "                            graph.update = False\n",
    "                        #print(\"eye:\", eye.shape, \"kp\", kp_coordinate)\n",
    "            \n",
    "            inas+=1\n",
    "            roi = frame[-80:-20, -120:-20,:]\n",
    "            roi[:] = graph.get_graph()\n",
    "            \n",
    "            roi2 = frame[-80:-20, 20:120,:]\n",
    "            roi2[:] = graph2.get_graph()\n",
    "            \n",
    "            cv2.imshow('showing', face_frame)\n",
    "            cv2.imshow('showing2', frame)\n",
    "            #if len(eye_coords) > 0:\n",
    "            #    pause_if_necesary(frame.shape[:2],face_frame.shape[:2],face_coords,eye_coords,eyes_frames)\n",
    "\n",
    "            #if len(eye_coords) > 0:\n",
    "            #    send_data(frame.shape[:2],face_frame.shape[:2],face_coords,eye_coords,eyes_frames,ms)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()   \n",
    "\n",
    "def eye_position(eye, eye_coord,i):\n",
    "    maximo = 1\n",
    "    B = 0\n",
    "    h,w = eye[0], eye[1]\n",
    "    w_R = eye_coord[1]/w\n",
    "    h_R = eye_coord[0]/h\n",
    "    # if(max_x.value<w_R):\n",
    "    #     max_x.value = w_R\n",
    "    # if(min_X.value>w_R):\n",
    "    #     min_X.value = w_R\n",
    "    # if(max_x.value>0):\n",
    "    #     try:\n",
    "    #         w_R = ((w_R-min_X.value*B)*maximo)/(max_x.value-min_X.value*B)\n",
    "    #     except ZeroDivisionError:\n",
    "    #         pass\n",
    "    \n",
    "    if(i==0):\n",
    "        xn0 = w_R\n",
    "        xnx = xn.value + (1/alpha.value)*(xn0-xn.value)\n",
    "        xn.value = xnx\n",
    "    alpha.value = alpha.value + 1\n",
    "    if(alpha.value>9):\n",
    "        alpha.value = 1\n",
    "    return  xn.value,h_R\n",
    "\n",
    "    \n",
    "def pause_if_necesary(frame, face_frame, face_coords, eye_coords,eyes):\n",
    "    fc = face_scale(frame, face_frame)\n",
    "    eyes_coords = []\n",
    "    for i in range(len(eye_coords)):\n",
    "        eyes_coords.append(eye_position(eyes[i],eye_coords[i]))\n",
    "        if(eyes_coords[i][0] > 1 or eyes_coords[i][1]>1):\n",
    "            print(\"This is wrong\", eyes_coords[i], eyes[i].shape, eye_coords[i])\n",
    "            show_img(frame,\"something wrong\")\n",
    "\n",
    "    #    eye_coords = list(map(lambda i,eye=eye,eye_coords=eye_coords: list(map(lambda coord,eye[i],i=i  : eye_position(eye,eye_coords),eye_coords)), np.arange(len(eye_coords)))\n",
    "    msj = str(fc)+\"_\"\n",
    "    msj += str(face_scale(frame,face_coords))+\"_\"\n",
    "    if len(eyes_coords) > 1:\n",
    "        msj += str(eyes_coords[0])+\"#\"+str(eyes_coords[1])\n",
    "    else:\n",
    "        msj += str(eyes_coords[0])+\"#\"+str(eyes_coords[0])\n",
    "    msj = msj.replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"\") #Limpiamos la cadena\n",
    "    \n",
    "    if fc>1 or face_scale(frame,face_coords)>1 :\n",
    "        print(\"frame:\", fc, \"face_coords\", face_coords, \"eyes ps\", eyes_coords)\n",
    "        show_img(frame,\"something wrong\")\n",
    "    \n",
    "def send_data(frame, face_frame, face_coords, eye_coords,eyes,ms):\n",
    "    fc = face_scale(frame, face_frame)\n",
    "    eyes_coords = []\n",
    "    for i in range(len(eye_coords)):\n",
    "        eyes_coords.append(eye_position(eyes[i],eye_coords[i]))\n",
    "\n",
    "    #    eye_coords = list(map(lambda i,eye=eye,eye_coords=eye_coords: list(map(lambda coord,eye[i],i=i  : eye_position(eye,eye_coords),eye_coords)), np.arange(len(eye_coords)))\n",
    "    msj = str(fc)+\"_\"\n",
    "    msj += str(face_scale(frame,face_coords))+\"_\"\n",
    "    if len(eyes_coords) > 1:\n",
    "        msj += str(eyes_coords[0])+\"#\"+str(eyes_coords[1])\n",
    "    else:\n",
    "        msj += str(eyes_coords[0])+\"#\"+str(eyes_coords[0])\n",
    "    msj = msj.replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"\") #Limpiamos la cadena\n",
    "\n",
    "    connection, _ = ms.accept()\n",
    "    if(connection != None):\n",
    "        connection.send(msj.encode())\n",
    "        print(msj)\n",
    "        connection.close()\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, width, height, sample_size = 100):\n",
    "        self.i = 0\n",
    "        self.iter = 0\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.graph = np.zeros((height, width, 3), np.uint8)\n",
    "        self.update = False\n",
    "        self.sample_size = sample_size\n",
    "        self.sample_count = 0\n",
    "        self.limits_upper = (0,0)\n",
    "        self.limits_lower = (200,200) #Numero grande para que pueda tomar un valor menor\n",
    "        self.size_of_frame = (0,0)\n",
    "        self.sampling_limits = True\n",
    "        \n",
    "    def update_frame(self, value_y, value_x,frame):\n",
    "        #We check the limits of the eye \n",
    "        if self.sampling_limits:\n",
    "            self.update_limits(value_y, value_x)\n",
    "            self.sample_count += 1\n",
    "            self.sampling_limits = self.sample_size > self.sample_count\n",
    "            if not self.sampling_limits:\n",
    "                print(\"============LIMITS1\",self.limits_upper,self.limits_lower,frame.shape )\n",
    "                self.size_of_frame = (self.limits_upper[0]-self.limits_lower[0],self.limits_upper[1]-self.limits_lower[1])\n",
    "        else:\n",
    "            self.i += 1\n",
    "            if self.i>5:\n",
    "                self.i = 0\n",
    "            #After sampling we start evaluating, if the limits goes over what we sample its refreshed again\n",
    "            adjusted_y = value_y-self.limits_lower[0]\n",
    "            adjusted_x = value_x-self.limits_lower[1]\n",
    "            \n",
    "            if adjusted_y > self.size_of_frame[0] or adjusted_y < 0:\n",
    "                self.update_limits(value_y,self.limits_upper[1])\n",
    "                self.size_of_frame = (self.limits_upper[0]-self.limits_lower[0],self.size_of_frame[1])\n",
    "                adjusted_y = value_y-self.limits_lower[0]\n",
    "                print(\"============LIMITS2\",self.limits_upper,self.limits_lower,frame.shape )\n",
    "            if adjusted_x > self.size_of_frame[1] or adjusted_x < 0:\n",
    "                self.update_limits(self.limits_upper[0],value_x)\n",
    "                self.size_of_frame = (self.size_of_frame[0],self.limits_upper[1]-self.limits_lower[1])\n",
    "                adjusted_x = value_x-self.limits_lower[1]\n",
    "                print(\"============LIMITS3\",self.limits_upper,self.limits_lower,frame.shape )\n",
    "                \n",
    "            point_x, point_y = eye_position(self.size_of_frame,(adjusted_y,adjusted_x),self.i)\n",
    "            print(point_x,point_y,value_x,value_y)\n",
    "            \n",
    "            graph_point_y = round(self.height*point_y) \n",
    "            if graph_point_y == self.graph.shape[0]:\n",
    "                graph_point_y-=1\n",
    "            graph_point_x = round(self.width*point_x) \n",
    "            if graph_point_x == self.graph.shape[1]:\n",
    "                graph_point_x-=1    \n",
    "            \n",
    "            self.graph[graph_point_y,graph_point_x,:] = 255\n",
    "\n",
    "    def update_limits(self, value_y, value_x):\n",
    "        if value_y > self.limits_upper[0]:\n",
    "            self.limits_upper = (value_y,self.limits_upper[1])\n",
    "        elif value_y < self.limits_lower[0]:\n",
    "            self.limits_lower = (value_y,self.limits_lower[1])\n",
    "        \n",
    "        if value_x > self.limits_upper[1]:\n",
    "            self.limits_upper = (self.limits_upper[0],value_x)\n",
    "        elif value_x < self.limits_lower[1]:\n",
    "            self.limits_lower = (self.limits_lower[0],value_x)\n",
    "            \n",
    "    def get_graph(self):\n",
    "        return self.graph\n",
    "        \n",
    "class Coordinates():\n",
    "    def __init__(self):\n",
    "        self.kps = []\n",
    "        self.iter_kps = []\n",
    "        self.iter_max\n",
    "        self.max = (0,0)\n",
    "        self.min = (0,0)\n",
    "        self.alpha = 0\n",
    "        self.prediction = 0\n",
    "    \n",
    "    def update_array(self, coords, frame):\n",
    "        adapted_x, adapted_y = face_scale(frame.shape[:2], coords)\n",
    "\n",
    "class Variable:\n",
    "    def _init_(self):\n",
    "        self.value = 0\n",
    "        \n",
    "        \n",
    "max_x = Variable()\n",
    "max_y = Variable()\n",
    "max_y.value = 1\n",
    "min_y = Variable()\n",
    "min_y.value = 0\n",
    "min_X = Variable()\n",
    "min_X.value = 1\n",
    "xn = Variable()\n",
    "xn.value = 0.4375\n",
    "alpha = Variable()\n",
    "alpha.value = 1\n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dca656",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pulsada\n",
      "pulsada\n",
      "pulsada\n",
      "pulsada\n",
      "pulsada\n",
      "pulsada\n",
      "pulsada\n",
      "pulsada\n",
      "pulsada\n",
      "pulsada\n",
      "pulsada\n",
      "pulsada\n",
      "pulsada\n",
      "pulsada\n",
      "pulsada\n",
      "pulsada\n",
      "pulsada\n",
      "pulsada\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import socket\n",
    "import numpy as np\n",
    "import time\n",
    "from pynput import keyboard as kb\n",
    "\n",
    "def pulsa(teclas):\n",
    "    print(\"pulsada\")\n",
    "    \n",
    "escuchador = kb.Listener(pulsa)\n",
    "escuchador.start()\n",
    "\n",
    "def main():\n",
    "    pulsada = 0\n",
    "    while True:\n",
    "        pulsada+=1\n",
    "    cap = cv2.VideoCapture(0)    \n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb7321df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyautogui\n",
      "  Downloading PyAutoGUI-0.9.53.tar.gz (59 kB)\n",
      "Collecting pymsgbox\n",
      "  Downloading PyMsgBox-1.0.9.tar.gz (18 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting PyTweening>=1.0.1\n",
      "  Downloading pytweening-1.0.4.tar.gz (14 kB)\n",
      "Collecting pyscreeze>=0.1.21\n",
      "  Downloading PyScreeze-0.1.28.tar.gz (25 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Collecting pygetwindow>=0.0.5\n",
      "  Downloading PyGetWindow-0.0.9.tar.gz (9.7 kB)\n",
      "Collecting mouseinfo\n",
      "  Downloading MouseInfo-0.1.3.tar.gz (10 kB)\n",
      "Collecting pyrect\n",
      "  Downloading PyRect-0.1.4.tar.gz (15 kB)\n",
      "Requirement already satisfied: Pillow>=6.2.1 in c:\\users\\moust\\anaconda3\\lib\\site-packages (from pyscreeze>=0.1.21->pyautogui) (8.2.0)\n",
      "Collecting pyperclip\n",
      "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "Building wheels for collected packages: pyautogui, pygetwindow, pyscreeze, PyTweening, mouseinfo, pymsgbox, pyperclip, pyrect\n",
      "Note: you may need to restart the kernel to use updated packages.  Building wheel for pyautogui (setup.py): started\n",
      "\n",
      "  Building wheel for pyautogui (setup.py): finished with status 'done'\n",
      "  Created wheel for pyautogui: filename=PyAutoGUI-0.9.53-py3-none-any.whl size=36583 sha256=3f5c478699015134284267da4794281e07f34545e00f1820b3a0c4dad82ae160\n",
      "  Stored in directory: c:\\users\\moust\\appdata\\local\\pip\\cache\\wheels\\54\\04\\f7\\55704a9d374ed923785a4fdc0ef00151fa25306b3b93345532\n",
      "  Building wheel for pygetwindow (setup.py): started\n",
      "  Building wheel for pygetwindow (setup.py): finished with status 'done'\n",
      "  Created wheel for pygetwindow: filename=PyGetWindow-0.0.9-py3-none-any.whl size=11078 sha256=cc79c8f1cdbb760c9f04e4a63b8c7569fc137ea36e59f12309f9967f846af3e7\n",
      "  Stored in directory: c:\\users\\moust\\appdata\\local\\pip\\cache\\wheels\\91\\e3\\04\\184bda98ec7f7d5f0ba1f372bcf7b3ba86325151ae1dd690fe\n",
      "  Building wheel for pyscreeze (PEP 517): started\n",
      "  Building wheel for pyscreeze (PEP 517): finished with status 'done'\n",
      "  Created wheel for pyscreeze: filename=PyScreeze-0.1.28-py3-none-any.whl size=13023 sha256=75b90e7d114db90ae5740c86abe55f05741ac34c9d677be72fef370dc39820c3\n",
      "  Stored in directory: c:\\users\\moust\\appdata\\local\\pip\\cache\\wheels\\b1\\b0\\5c\\9fb5beb2d6c708479a670e92f4ab3b54523a15c9cd4a46e24e\n",
      "  Building wheel for PyTweening (setup.py): started\n",
      "  Building wheel for PyTweening (setup.py): finished with status 'done'\n",
      "  Created wheel for PyTweening: filename=pytweening-1.0.4-py3-none-any.whl size=5825 sha256=f832dc4298f090acb4dafb1902464fc07edabbec0f9380b9196093af26089cb3\n",
      "  Stored in directory: c:\\users\\moust\\appdata\\local\\pip\\cache\\wheels\\a2\\1b\\69\\dc477653ccc19228bf53af76c623e4e82e5dc1b6f78d5c4d35\n",
      "  Building wheel for mouseinfo (setup.py): started\n",
      "  Building wheel for mouseinfo (setup.py): finished with status 'done'\n",
      "  Created wheel for mouseinfo: filename=MouseInfo-0.1.3-py3-none-any.whl size=10905 sha256=7060d637119aa1ff427b41c9ab0a184d9460280ce794eae1f96d8b6d093db808\n",
      "  Stored in directory: c:\\users\\moust\\appdata\\local\\pip\\cache\\wheels\\d1\\72\\fb\\35f403de66285df8ecca7049bcc61bfb57aba0f76d1f08f7eb\n",
      "  Building wheel for pymsgbox (PEP 517): started\n",
      "  Building wheel for pymsgbox (PEP 517): finished with status 'done'\n",
      "  Created wheel for pymsgbox: filename=PyMsgBox-1.0.9-py3-none-any.whl size=7420 sha256=bfb7c06911d37220706596ec4e1dc03489999cc71beb2f1e770ffd9d237765f8\n",
      "  Stored in directory: c:\\users\\moust\\appdata\\local\\pip\\cache\\wheels\\91\\28\\0d\\f4eb606d38276836237d6dc2abf094241e6db5682a126e0389\n",
      "  Building wheel for pyperclip (setup.py): started\n",
      "  Building wheel for pyperclip (setup.py): finished with status 'done'\n",
      "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11107 sha256=f9f584cca9371d821f63a4841523bc753c378f113fd7da4bfea51efaa1e4f6e5\n",
      "  Stored in directory: c:\\users\\moust\\appdata\\local\\pip\\cache\\wheels\\7f\\1a\\65\\84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
      "  Building wheel for pyrect (setup.py): started\n",
      "  Building wheel for pyrect (setup.py): finished with status 'done'\n",
      "  Created wheel for pyrect: filename=PyRect-0.1.4-py2.py3-none-any.whl size=9547 sha256=c7dec6523010509a491b80c67da4ce1bba91bd0f6130926e4ee30477e9d71eee\n",
      "  Stored in directory: c:\\users\\moust\\appdata\\local\\pip\\cache\\wheels\\d1\\e4\\47\\c62f8291b16b6df7e89ac885881ff71f35ca04c6e384251de9\n",
      "Successfully built pyautogui pygetwindow pyscreeze PyTweening mouseinfo pymsgbox pyperclip pyrect\n",
      "Installing collected packages: pyrect, pyperclip, PyTweening, pyscreeze, pymsgbox, pygetwindow, mouseinfo, pyautogui\n",
      "Successfully installed PyTweening-1.0.4 mouseinfo-0.1.3 pyautogui-0.9.53 pygetwindow-0.0.9 pymsgbox-1.0.9 pyperclip-1.8.2 pyrect-0.1.4 pyscreeze-0.1.28\n"
     ]
    }
   ],
   "source": [
    "pip install pyautogui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14d6be1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import socket\n",
    "import numpy as np\n",
    "import time\n",
    "import pyautogui\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "def show_img(img, name='my image'):\n",
    "    cv2.imshow(name,img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "#Iteración 3\n",
    "def detect_eyes(img, classifier):\n",
    "    gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    eyes = classifier.detectMultiScale(gray_frame, 1.07, 3) # detect eyes\n",
    "    width = np.size(img, 1) # get face frame width\n",
    "    height = np.size(img, 0) # get face frame height\n",
    "    left_eye = None\n",
    "    right_eye = None\n",
    "    for (x, y, w, h) in eyes:\n",
    "        if y > height / 2 or y<.3*height:\n",
    "            pass\n",
    "        eyecenter = x + w / 2  # get the eye center\n",
    "        if eyecenter < width * 0.5:\n",
    "            left_eye = img[y:y + h, x:x + w]\n",
    "        else:\n",
    "            right_eye = img[y:y + h, x:x + w]\n",
    "    return left_eye, right_eye\n",
    "\n",
    "def detect_faces(img, classifier):\n",
    "    gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    coords = classifier.detectMultiScale(gray_frame, 1.3, 5)\n",
    "    x,y = 0,0\n",
    "    if len(coords) > 1:\n",
    "        biggest = (0, 0, 0, 0)\n",
    "        for i in coords:\n",
    "            if i[3] > biggest[3]:\n",
    "                biggest = i\n",
    "        biggest = np.array([i], np.int32)\n",
    "    elif len(coords) == 1:\n",
    "        biggest = coords\n",
    "    else:\n",
    "        return None, None\n",
    "    for (x, y, w, h) in biggest:\n",
    "        frame = img[y:y + h, x:x + w]\n",
    "    return frame, (y, x)\n",
    "\n",
    "def cut_eyebrows(img):\n",
    "    height, width = img.shape[:2]\n",
    "    eyebrow_h = int(height / 5)\n",
    "    img = img[eyebrow_h:height, 0:width]  # cut eyebrows out (15 px)\n",
    "    return img\n",
    "\n",
    "def blob_process(img, detector):\n",
    "    _, img = cv2.threshold(img, 42, 250, cv2.THRESH_BINARY)\n",
    "    img = cv2.erode(img, None, iterations=5)\n",
    "    img = cv2.dilate(img, None, iterations=6)\n",
    "    img = cv2.medianBlur(img, 7)\n",
    "    keypoints = detector.detect(img)\n",
    "    return keypoints\n",
    "\n",
    "def my_testing(keypoints,img):\n",
    "    if len(keypoints)>0:\n",
    "        print(\"========pausa eye:\",img.shape)\n",
    "        kp_coordinate = (0,0)\n",
    "        kp_size = 0\n",
    "        for kp in keypoints:\n",
    "            if kp.size > kp_size:\n",
    "                kp_size = kp.size\n",
    "                kp_coordinate = kp.pt\n",
    "        print(\"=================Size:\",kp_size)\n",
    "        print(\"=================coordinate:\",kp_coordinate)\n",
    "        show_img(img,\"0\")\n",
    "\n",
    "def main():\n",
    "    #ms = socket.socket()\n",
    "    #ms.bind(('localhost',5000))\n",
    "    #ms.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)\n",
    "    #ms.listen(5)\n",
    "    blob_detector_params = cv2.SimpleBlobDetector_Params()\n",
    "    blob_detector_params.filterByArea = True\n",
    "    blob_detector_params.maxArea = 150\n",
    "    blob_detector = cv2.SimpleBlobDetector_create(blob_detector_params)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    inas=0\n",
    "    graph = Graph(100, 60)\n",
    "    graph2 = Graph(100, 60)\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        face_frame, face_coords = detect_faces(frame, face_cascade)\n",
    "        if face_frame is not None:\n",
    "            eyes = detect_eyes(face_frame, eye_cascade)\n",
    "            eye_coords = []\n",
    "            eyes_frames = []\n",
    "            for index,eye in enumerate(eyes):\n",
    "                if eye is not None:\n",
    "                    if index == 0:\n",
    "                        graph2.update = True\n",
    "                    if index == 1:\n",
    "                        graph.update = True\n",
    "                    eye = cut_eyebrows(eye)\n",
    "                    keypoints = blob_process(eye, blob_detector)\n",
    "                    eye = cv2.drawKeypoints(eye, keypoints, eye, (0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "                    kp_coordinate = (0,0)\n",
    "                    kp_size = 0\n",
    "                    for kp in keypoints:\n",
    "                        if kp.size > kp_size:\n",
    "                            kp_size = kp.size\n",
    "                            kp_coordinate = kp.pt\n",
    "                    if len(keypoints) > 0:\n",
    "                        eyes_frames.append(eye)\n",
    "                        eye_coords.append(kp_coordinate)\n",
    "                        kp_x, kp_y = face_scale(eye.shape[:2],(kp_coordinate[0],kp_coordinate[1]))\n",
    "                        if graph2.update:\n",
    "                            graph2.update_frame(kp_y,kp_x,eye)\n",
    "                            graph2.update = False\n",
    "                        if graph.update:\n",
    "                            graph.update_frame(kp_y,kp_x,eye)\n",
    "                            graph.update = False\n",
    "                    #print(\"eye:\", eye.shape, \"kp\", kp_coordinate)\n",
    "            \n",
    "            inas+=1\n",
    "            roi = frame[-80:-20, -120:-20,:]\n",
    "            roi[:] = graph.get_graph()\n",
    "            \n",
    "            roi2 = frame[-80:-20, 20:120,:]\n",
    "            roi2[:] = graph2.get_graph()\n",
    "            \n",
    "            cv2.imshow('showing', face_frame)\n",
    "            #cv2.imshow('showing2', frame)\n",
    "            #if len(eye_coords) > 0:\n",
    "            #    pause_if_necesary(frame.shape[:2],face_frame.shape[:2],face_coords,eye_coords,eyes_frames)\n",
    "\n",
    "            #if len(eye_coords) > 0:\n",
    "            #    send_data(frame.shape[:2],face_frame.shape[:2],face_coords,eye_coords,eyes_frames,ms)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()   \n",
    "\n",
    "#Face coords\n",
    "def face_scale(frame, face):\n",
    "    width = face[1]/frame[1]\n",
    "    height = face[0]/frame[0]\n",
    "    return width, height\n",
    "\n",
    "def eye_position(eye, eye_coord):\n",
    "    h,w = eye.shape[0]-eye.shape[0]*.05, eye.shape[1]-eye.shape[1]*.1\n",
    "    w_R = eye_coord[1]/w\n",
    "    h_R = eye_coord[0]/h\n",
    "    \n",
    "    return w_R,h_R\n",
    "\n",
    "    \n",
    "def pause_if_necesary(frame, face_frame, face_coords, eye_coords,eyes):\n",
    "    fc = face_scale(frame, face_frame)\n",
    "    eyes_coords = []\n",
    "    for i in range(len(eye_coords)):\n",
    "        eyes_coords.append(eye_position(eyes[i],eye_coords[i]))\n",
    "        if(eyes_coords[i][0] > 1 or eyes_coords[i][1]>1):\n",
    "            print(\"This is wrong\", eyes_coords[i], eyes[i].shape, eye_coords[i])\n",
    "            show_img(frame,\"something wrong\")\n",
    "\n",
    "    #    eye_coords = list(map(lambda i,eye=eye,eye_coords=eye_coords: list(map(lambda coord,eye[i],i=i  : eye_position(eye,eye_coords),eye_coords)), np.arange(len(eye_coords)))\n",
    "    msj = str(fc)+\"_\"\n",
    "    msj += str(face_scale(frame,face_coords))+\"_\"\n",
    "    if len(eyes_coords) > 1:\n",
    "        msj += str(eyes_coords[0])+\"#\"+str(eyes_coords[1])\n",
    "    else:\n",
    "        msj += str(eyes_coords[0])+\"#\"+str(eyes_coords[0])\n",
    "    msj = msj.replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"\") #Limpiamos la cadena\n",
    "    \n",
    "    if fc>1 or face_scale(frame,face_coords)>1 :\n",
    "        print(\"frame:\", fc, \"face_coords\", face_coords, \"eyes ps\", eyes_coords)\n",
    "        show_img(frame,\"something wrong\")\n",
    "    \n",
    "def send_data(frame, face_frame, face_coords, eye_coords,eyes,ms):\n",
    "    fc = face_scale(frame, face_frame)\n",
    "    eyes_coords = []\n",
    "    for i in range(len(eye_coords)):\n",
    "        eyes_coords.append(eye_position(eyes[i],eye_coords[i]))\n",
    "\n",
    "    #    eye_coords = list(map(lambda i,eye=eye,eye_coords=eye_coords: list(map(lambda coord,eye[i],i=i  : eye_position(eye,eye_coords),eye_coords)), np.arange(len(eye_coords)))\n",
    "    msj = str(fc)+\"_\"\n",
    "    msj += str(face_scale(frame,face_coords))+\"_\"\n",
    "    if len(eyes_coords) > 1:\n",
    "        msj += str(eyes_coords[0])+\"#\"+str(eyes_coords[1])\n",
    "    else:\n",
    "        msj += str(eyes_coords[0])+\"#\"+str(eyes_coords[0])\n",
    "    msj = msj.replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"\") #Limpiamos la cadena\n",
    "\n",
    "    connection, _ = ms.accept()\n",
    "    if(connection != None):\n",
    "        connection.send(msj.encode())\n",
    "        print(msj)\n",
    "        connection.close()\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, width, height, sample_size = 100):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.graph = np.zeros((height, width, 3), np.uint8)\n",
    "        self.update = False\n",
    "        self.sample_size = sample_size\n",
    "        self.sample_count = 0\n",
    "        self.limits_upper = (0,0)\n",
    "        self.limits_lower = (200,200) #Numero grande para que pueda tomar un valor menor\n",
    "        self.size_of_frame = (0,0)\n",
    "        self.sampling_limits = True\n",
    "        \n",
    "    def update_frame(self, value_y, value_x,frame):\n",
    "        #We check the limits of the eye \n",
    "        if self.sampling_limits:\n",
    "            self.update_limits(value_y, value_x)\n",
    "            self.sample_count += 1\n",
    "            self.sampling_limits = self.sample_size > self.sample_count\n",
    "            if not self.sampling_limits:\n",
    "                print(\"============LIMITS1\",self.limits_upper,self.limits_lower,frame.shape )\n",
    "                self.size_of_frame = (self.limits_upper[0]-self.limits_lower[0],self.limits_upper[1]-self.limits_lower[1])\n",
    "        else:\n",
    "            #After sampling we start evaluating, if the limits goes over what we sample its refreshed again\n",
    "            adjusted_y = value_y-self.limits_lower[0]\n",
    "            adjusted_x = value_x-self.limits_lower[1]\n",
    "            \n",
    "            if adjusted_y > self.size_of_frame[0] or adjusted_y < 0:\n",
    "                self.update_limits(value_y,self.limits_upper[1])\n",
    "                self.size_of_frame = (self.limits_upper[0]-self.limits_lower[0],self.size_of_frame[1])\n",
    "                adjusted_y = value_y-self.limits_lower[0]\n",
    "                print(\"============LIMITS2\",self.limits_upper,self.limits_lower,frame.shape )\n",
    "            if adjusted_x > self.size_of_frame[1] or adjusted_x < 0:\n",
    "                self.update_limits(self.limits_upper[0],value_x)\n",
    "                self.size_of_frame = (self.size_of_frame[0],self.limits_upper[1]-self.limits_lower[1])\n",
    "                adjusted_x = value_x-self.limits_lower[1]\n",
    "                print(\"============LIMITS3\",self.limits_upper,self.limits_lower,frame.shape )\n",
    "                \n",
    "            point_x, point_y = face_scale(self.size_of_frame,(adjusted_y,adjusted_x))\n",
    "            print(point_x,point_y,value_x,value_y)\n",
    "            \n",
    "            graph_point_y = round(self.height*point_y) \n",
    "            if graph_point_y == self.graph.shape[0]:\n",
    "                graph_point_y-=1\n",
    "            graph_point_x = round(self.width*point_x) \n",
    "            if graph_point_x == self.graph.shape[1]:\n",
    "                graph_point_x-=1    \n",
    "            \n",
    "            self.graph[graph_point_y,graph_point_x,:] = 255\n",
    "\n",
    "    def update_limits(self, value_y, value_x):\n",
    "        if value_y > self.limits_upper[0]:\n",
    "            self.limits_upper = (value_y,self.limits_upper[1])\n",
    "        elif value_y < self.limits_lower[0]:\n",
    "            self.limits_lower = (value_y,self.limits_lower[1])\n",
    "        \n",
    "        if value_x > self.limits_upper[1]:\n",
    "            self.limits_upper = (self.limits_upper[0],value_x)\n",
    "        elif value_x < self.limits_lower[1]:\n",
    "            self.limits_lower = (self.limits_lower[0],value_x)\n",
    "            \n",
    "    def get_graph(self):\n",
    "        return self.graph\n",
    "        \n",
    "class Coordinates():\n",
    "    def __init__(self):\n",
    "        self.kps = []\n",
    "        self.iter_kps = []\n",
    "        self.iter_max\n",
    "        self.max = (0,0)\n",
    "        self.min = (0,0)\n",
    "        self.alpha = 0\n",
    "        self.prediction = 0\n",
    "    \n",
    "    def update_array(self, coords, frame):\n",
    "        adapted_x, adapted_y = face_scale(frame.shape[:2], coords)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62ae0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import socket\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')\n",
    "\n",
    "def show_img(img, name='my image'):\n",
    "    cv2.imshow(name,img)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "#Iteración 3\n",
    "def detect_eyes(img, classifier):\n",
    "    gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    eyes = classifier.detectMultiScale(gray_frame, 1.07, 3) # detect eyes\n",
    "    width = np.size(img, 1) # get face frame width\n",
    "    height = np.size(img, 0) # get face frame height\n",
    "    left_eye = None\n",
    "    right_eye = None\n",
    "    for (x, y, w, h) in eyes:\n",
    "        if y > height / 2:\n",
    "            pass\n",
    "        eyecenter = x + w / 2  # get the eye center\n",
    "        if eyecenter < width * 0.5:\n",
    "            left_eye = img[y:y + h, x:x + w]\n",
    "        else:\n",
    "            right_eye = img[y:y + h, x:x + w]\n",
    "    return left_eye, right_eye\n",
    "\n",
    "def detect_faces(img, classifier):\n",
    "    gray_frame = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    coords = classifier.detectMultiScale(gray_frame, 1.3, 5)\n",
    "    x,y = 0,0\n",
    "    if len(coords) > 1:\n",
    "        biggest = (0, 0, 0, 0)\n",
    "        for i in coords:\n",
    "            if i[3] > biggest[3]:\n",
    "                biggest = i\n",
    "        biggest = np.array([i], np.int32)\n",
    "    elif len(coords) == 1:\n",
    "        biggest = coords\n",
    "    else:\n",
    "        return None, None\n",
    "    for (x, y, w, h) in biggest:\n",
    "        frame = img[y:y + h, x:x + w]\n",
    "    return frame, (y, x)\n",
    "\n",
    "def cut_eyebrows(img):\n",
    "    height, width = img.shape[:2]\n",
    "    eyebrow_h = int(height / 5)\n",
    "    img = img[eyebrow_h:height, 0:width]  # cut eyebrows out (15 px)\n",
    "    return img\n",
    "\n",
    "def blob_process(img, detector):\n",
    "    _, img = cv2.threshold(img, 42, 250, cv2.THRESH_BINARY)\n",
    "    img = cv2.erode(img, None, iterations=5)\n",
    "    img = cv2.dilate(img, None, iterations=6)\n",
    "    img = cv2.medianBlur(img, 7)\n",
    "    keypoints = detector.detect(img)\n",
    "    return keypoints\n",
    "\n",
    "def my_testing(keypoints,img):\n",
    "    if len(keypoints)>0:\n",
    "        print(\"========pausa eye:\",img.shape)\n",
    "        kp_coordinate = (0,0)\n",
    "        kp_size = 0\n",
    "        for kp in keypoints:\n",
    "            if kp.size > kp_size:\n",
    "                kp_size = kp.size\n",
    "                kp_coordinate = kp.pt\n",
    "        print(\"=================Size:\",kp_size)\n",
    "        print(\"=================coordinate:\",kp_coordinate)\n",
    "        show_img(img,\"0\")\n",
    "\n",
    "        \n",
    "        \n",
    "class Variable:\n",
    "    def _init_(self):\n",
    "        self.value = 0\n",
    "\n",
    "\n",
    "def main():\n",
    "   \n",
    "    ms = socket.socket()\n",
    "    ms.bind(('localhost',5000))\n",
    "    ms.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)\n",
    "    ms.listen(5)\n",
    "    blob_detector_params = cv2.SimpleBlobDetector_Params()\n",
    "    blob_detector_params.filterByArea = True\n",
    "    blob_detector_params.maxArea = 150\n",
    "    blob_detector = cv2.SimpleBlobDetector_create(blob_detector_params)\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    inas=0\n",
    "    while True:\n",
    "        _, frame = cap.read()\n",
    "        face_frame, face_coords = detect_faces(frame, face_cascade)\n",
    "        if face_frame is not None:\n",
    "            eyes = detect_eyes(face_frame, eye_cascade)\n",
    "            eye_coords = []\n",
    "            eyes_frames = []\n",
    "            for eye in eyes:\n",
    "                if eye is not None:\n",
    "                    eye = cut_eyebrows(eye)\n",
    "                    keypoints = blob_process(eye, blob_detector)\n",
    "                  \n",
    "                    eye = cv2.drawKeypoints(eye, keypoints, eye, (0, 0, 255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "\n",
    "                    kp_coordinate = (0,0)\n",
    "                    kp_size = 0\n",
    "                    for kp in keypoints:\n",
    "                        if kp.size > kp_size:\n",
    "                            kp_size = kp.size\n",
    "                            kp_coordinate = kp.pt\n",
    "                    if len(keypoints) > 0:\n",
    "                        eyes_frames.append(eye)\n",
    "                        eye_coords.append(kp_coordinate)\n",
    "            inas+=1\n",
    "            cv2.imshow('showing', face_frame)\n",
    "            if len(eye_coords) > 0:\n",
    "                send_data(frame.shape[:2],face_frame.shape[:2],face_coords,eye_coords,eyes_frames,ms)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()   \n",
    "\n",
    "#Face coords\n",
    "def face_scale(frame, face):\n",
    "    width = face[1]/frame[1]\n",
    "    height = face[0]/frame[0]\n",
    "    return width, height\n",
    "\n",
    "def eye_position(eye, eye_coord,i):\n",
    "    maximo = 1\n",
    "    B = 0\n",
    "    h,w = eye.shape[0]-eye.shape[0]*.05, eye.shape[1]-eye.shape[1]*.1\n",
    "    w_R = eye_coord[0]/w\n",
    "    h_R = eye_coord[1]/h\n",
    "    if(max_x.value<w_R):\n",
    "        max_x.value = w_R\n",
    "    if(min_X.value>w_R):\n",
    "        min_X.value = w_R\n",
    "    # if(min_X.value>0):\n",
    "    #     w_R = (w_R*maximo)/max_x.value\n",
    "    if(max_x.value>0 and min_X.value>1):\n",
    "        w_R = ((w_R-min_X.value*B)*maximo)/(max_x.value-min_X.value*B)\n",
    "    if(i==0):\n",
    "        xn0 = w_R\n",
    "        xnx = xn.value + 0.5*(xn0-xn.value)\n",
    "        xn.value = xnx\n",
    "       \n",
    "   \n",
    "    return xn.value,h_R\n",
    "\n",
    "def send_data(frame, face, face_coords, eye_coords,eyes,ms):\n",
    "    fc = face_scale(frame, face)\n",
    "    eyes_coords = []\n",
    "    for i in range(len(eye_coords)):\n",
    "        eyes_coords.append(eye_position(eyes[i],eye_coords[i],i))\n",
    "    #o = input(eyes_coords)\n",
    "    #eyes_coords[0][0] = xn\n",
    "    # plt.axis([0,1,0,1])\n",
    "    # plt.ion()\n",
    "    # colors = ['bo','ro']\n",
    "    # for i in range(len(eyes_coords)):\n",
    "    #     plt.plot(xn,eyes_coords[i][1],colors[i])\n",
    "    # plt.draw()\n",
    "    # plt.show()\n",
    "    # #plt.show()             #this plots correctly, but blocks execution.\n",
    "    # plt.pause(0.001) \n",
    "    #    eye_coords = list(map(lambda i,eye=eye,eye_coords=eye_coords: list(map(lambda coord,eye[i],i=i  : eye_position(eye,eye_coords),eye_coords)), np.arange(len(eye_coords)))\n",
    "    msj = str(fc)+\"_\"\n",
    "    msj += str(face_scale(frame,face_coords))+\"_\"\n",
    "    if len(eyes_coords) > 1:\n",
    "        msj += str(eyes_coords[0])+\"#\"+str(eyes_coords[1])\n",
    "    else:\n",
    "        msj += str(eyes_coords[0])+\"#\"+str(eyes_coords[0])\n",
    "    msj = msj.replace(\"(\",\"\").replace(\")\",\"\").replace(\" \",\"\") #Limpiamos la cadena\n",
    "    #msj = msj.replace(\"[\",\"\").replace(\"]\",\"\")\n",
    "    connection, _ = ms.accept()\n",
    "    if(connection != None):\n",
    "        connection.send(msj.encode())\n",
    "        #print(msj)\n",
    "        print(msj)\n",
    "        connection.close()\n",
    "    \n",
    "max_x = Variable()\n",
    "min_X = Variable()\n",
    "min_X.value = 1\n",
    "xn = Variable()\n",
    "xn.value = 0.4375\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfb8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "============LIMITS1 (41.55253982543945, 20.98297691345215) (17.58108139038086, 12.07575798034668) (40, 50, 3)\n",
    "============LIMITS1 (41.55253982543945, 20.98297691345215) (17.58108139038086, 12.07575798034668) (41, 51, 3)\n",
    "class Graph:\n",
    "    def __init__(self, width, height):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.graph = np.zeros((height, width, 3), np.uint8)\n",
    "\n",
    "    def update_frame(self, value_y, value_x):\n",
    "        \n",
    "        new_graph = self.graph\n",
    "        new_graph[self.height*value_y,self.height*value_x,:] = 255\n",
    "        self.graph = new_graph\n",
    "\n",
    "    def get_graph(self):\n",
    "        return self.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1576c564",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-ac29dcb244d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;31m# Capture frame-by-frame\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m640\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m480\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Graph:\n",
    "    def __init__(self, width, height):\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.graph = np.zeros((height, width, 3), np.uint8)\n",
    "\n",
    "    def update_frame(self, value):\n",
    "        if value < 0:\n",
    "            value = 0\n",
    "        elif value >= self.height:\n",
    "            value = self.height - 1\n",
    "        new_graph = np.zeros((self.height, self.width, 3), np.uint8)\n",
    "        new_graph[:,:-1,:] = self.graph[:,1:,:]\n",
    "        new_graph[self.height - value:,-1,:] = 255\n",
    "        self.graph = new_graph\n",
    "\n",
    "    def get_graph(self):\n",
    "        return self.graph\n",
    "\n",
    "\n",
    "# Setup camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "# Set a smaller resolution\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "\n",
    "graph = Graph(100, 60)\n",
    "\n",
    "prev_frame = np.zeros((480, 640), np.uint8)\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (25, 25), None)\n",
    "    diff = cv2.absdiff(prev_frame, gray)\n",
    "    difference = np.sum(diff)\n",
    "    prev_frame = gray\n",
    "\n",
    "    graph.update_frame(int(difference/42111))\n",
    "    roi = frame[-80:-20, -120:-20,:]\n",
    "    roi[:] = graph.get_graph()\n",
    "\n",
    "    cv2.putText(frame, \"...wanted a live graph\", (20, 430), cv2.FONT_HERSHEY_PLAIN, 1.8, (200, 200, 200), 2)\n",
    "    cv2.putText(frame, \"...measures motion in frame\", (20, 460), cv2.FONT_HERSHEY_PLAIN, 1.8, (200, 200, 200), 2)\n",
    "    cv2.imshow(\"Webcam\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fea9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
